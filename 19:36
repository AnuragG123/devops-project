import boto3
from datetime import datetime, timedelta

def delete_objects_in_folder(bucket_name, prefix):
    s3 = boto3.client('s3')
    deleted_objects = []

    # List objects in the folder
    response = s3.list_objects_v2(Bucket=bucket_name, Prefix=prefix)

    # Iterate through objects and delete them
    if 'Contents' in response:
        for obj in response['Contents']:
            key = obj['Key']
            print(f"Deleting object: {key}")
            s3.delete_object(Bucket=bucket_name, Key=key)
            deleted_objects.append(key)

    return deleted_objects

def delete_folders(bucket_name, prefix, older_than_years):
    s3 = boto3.client('s3')
    deleted_folders = []

    # Calculate cutoff date
    cutoff_date = datetime.now() - timedelta(days=older_than_years*365)

    # List objects in the bucket with the given prefix
    response = s3.list_objects_v2(Bucket=bucket_name, Prefix=prefix, Delimiter='/')

    # Iterate through region_number folders
    if 'CommonPrefixes' in response:
        for region_folder in response['CommonPrefixes']:
            region_prefix = region_folder['Prefix']
            # List objects in the region folder
            region_response = s3.list_objects_v2(Bucket=bucket_name, Prefix=region_prefix, Delimiter='/')
            # Iterate through YR_MO folders in the region folder
            if 'CommonPrefixes' in region_response:
                for yr_mo_folder in region_response['CommonPrefixes']:
                    yr_mo_prefix = yr_mo_folder['Prefix']
                    parts = yr_mo_prefix.split('=')
                    if len(parts) == 2:
                        yr_mo_name = parts[-1][:6]  # Extract YR_MO, adjust the number according to the actual length of the folder name
                        try:
                            yr_mo_date = datetime.strptime(yr_mo_name, "%Y%m")  # Adjust the format according to your actual naming convention
                            if yr_mo_date < cutoff_date:
                                print(f"Deleting folder: {yr_mo_prefix}")
                                # Delete objects in the YR_MO folder
                                deleted_objects = delete_objects_in_folder(bucket_name, yr_mo_prefix)
                                # Delete the folder itself if it's empty after deleting objects
                                if not deleted_objects:
                                    s3.delete_object(Bucket=bucket_name, Key=yr_mo_prefix)
                                deleted_folders.append(yr_mo_prefix)
                        except ValueError:
                            # Skip if yr_mo_name is not a valid date
                            pass

    return deleted_folders

def lambda_handler(event, context):
    bucket_name = event['bucket']
    prefix = event['prefix']
    older_than_years = event.get('older_than_years', 8)

    deleted_folders = delete_folders(bucket_name, prefix, older_than_years)

    return {
        "deleted_folders": deleted_folders
    }

# Example usage
if __name__ == "__main__":
    # For local testing
    event = {
        "bucket": "anuragwarangal",
        "prefix": "converted/loss/on533/region_number=",
        "older_than_years": 8
    }
    response = lambda_handler(event, None)
    deleted_folders = response.get('deleted_folders', [])
    if deleted_folders:
        print("Deleted folders:")
        for folder in deleted_folders:
            print(folder)
    else:
        print("No folders deleted.")
